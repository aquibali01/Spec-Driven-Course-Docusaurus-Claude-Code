# Physical AI & Humanoid Robotics  
**Spec-Driven Course | Docusaurus + Claude Code**

## Overview
This repository contains a **spec-driven technical course** on **Physical AI & Humanoid Robotics**, focused on bridging AI systems with the physical world. The course is authored using **Spec-Kit Plus** and **Claude Code**, published with **Docusaurus**, and designed for AI and robotics engineers.

The curriculum progresses from robot middleware (ROS 2), to digital twins and simulation, to advanced perception and navigation, and finally to **Vision-Language-Action (VLA)** systems powered by LLMs.

---

## Course Structure

### Module 1: The Robotic Nervous System (ROS 2)
- ROS 2 architecture, nodes, topics, services
- Bridging Python AI agents with robot controllers
- Humanoid modeling using URDF

### Module 2: The Digital Twin (Gazebo & Unity)
- Physics-based simulation
- Sensor simulation (LiDAR, depth, IMU)
- Humanâ€“robot interaction environments

### Module 3: The AI-Robot Brain (NVIDIA Isaacâ„¢)
- Isaac Sim and synthetic data
- Isaac ROS and VSLAM
- Navigation with Nav2

### Module 4: Vision-Language-Action (VLA)
- Multimodal robot intelligence
- Voice-to-action pipelines
- LLM-based task planning
- Capstone: Autonomous humanoid execution

---

## Tech Stack
- **Documentation:** Docusaurus (MDX)
- **Specs & Governance:** Spec-Kit Plus
- **Authoring Agent:** Claude Code
- **Robotics:** ROS 2, Gazebo, Unity
- **AI & Simulation:** NVIDIA Isaac Sim, Isaac ROS
- **LLMs & Speech:** OpenAI Whisper (conceptual)
- **Deployment:** GitHub Pages

---

## Spec-Driven Workflow

/sp.constitution defines global rules and success criteria

/sp.specify defines module-level scope and intent

/sp.plan defines execution and validation strategy

Claude Code consumes these specs to generate consistent, auditable content.

Status

ðŸš§ Active development

âœ” Spec-complete

âœ” Docusaurus-ready
